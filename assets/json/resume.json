{
  "basics": {
    "name": "Cheng Chien",
    "label": "",
    "image": "",
    "email": "chengchien1999@gmail.com",
    "phone": "(886) 989819022",
    "url": "https://www.linkedin.com/in/cchien1999",
    "summary": "A German-born theoretical physicist, widely ranked among the greatest and most influential scientists of all time",
    "location": {
      "address": "2712 Broadway St",
      "postalCode": "CA 94115",
      "city": "San Francisco",
      "countryCode": "US",
      "region": "California"
    },
    "profiles": [
      {
        "network": "Twitter",
        "username": "AlbertEinstein",
        "url": "https://twitter.com/AlbertEinstein"
      }
    ]
  },
  "work": [
    {
      "name": "Institute for Advanced Study, Princeton University",
      "position": "Professor of Theoretical Physics",
      "url": "https://example.com",
      "startDate": "1933-01-01",
      "endDate": "1955-01-01",
      "summary": "Teaching at Palmer Physical Laboratory (now 302 Frist Campus Center). While not a professor at Princeton, I associated with the physics professors and continued to give lectures on campus.",
      "highlights": ["Relativity"]
    }
  ],
  "volunteer": [
    {
      "organization": "People's Climate March",
      "position": "Lead Organizer",
      "url": "https://example.com",
      "startDate": "2014-04-01",
      "endDate": "2015-07-01",
      "summary": "Lead organizer for the New York City branch of the People's Climate March, the largest climate march in history.",
      "highlights": ["Awarded 'Climate Hero' award by Greenpeace for my efforts organizing the march.", "Men of the year 2014 by Time magazine"]
    }
  ],
  "education": [
    {
      "institution": "National Yang Ming Chiao Tung University, Taiwan",
      "location": "Taiwan",
      "url": "https://www.nycu.edu.tw/nycu/en/index",
      "area": "Computer Sciences",
      "studyType": "Master",
      "startDate": "2022",
      "endDate": "",
      "score": "10",
      "courses": ["Theory of Relativity"]
    },
    {
      "institution": "National Sun Yat-sen University, Taiwan",
      "location": "Taiwan",
      "url": "https://www.nsysu.edu.tw/?Lang=en",
      "area": "Computer Science and Engineering",
      "studyType": "Bachelor",
      "startDate": "2018",
      "endDate": "2022",
      "score": "10",
      "courses": ["Theory of Relativity"]
    }
  ],
  "awards": [
    {
      "title": "Nobel Prize in Physics",
      "date": "1921-11-01",
      "awarder": "Royal Swedish Academy of Sciences",
      "url": "https://www.nobelprize.org/prizes/physics/1921/einstein/biographical/",
      "summary": "The Nobel Prizes are five separate prizes that, according to Alfred Nobel's will of 1895, are awarded to 'those who, during the preceding year, have conferred the greatest benefit to humankind.'"
    }
  ],
  "certificates": [
    {
      "name": "Machine Learning",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-location-dot"
    },
    {
      "name": "Quantum Computing",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-tag"
    },
    {
      "name": "Quantum Information",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-envelope"
    },
    {
      "name": "Quantum Cryptography",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-hashtag"
    },
    {
      "name": "Quantum Communication",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-calendar"
    },
    {
      "name": "Quantum Teleportation",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-clipboard-check"
    }
  ],
  "skills": [
    {
      "name": "Programming",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "Python",
        "C",
        "C++"
      ]
    },
    {
      "name": "Machine Learning",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "Pytorch"
      ]
    }
  ],
  "languages": [
    {
      "language": "Mandarin",
      "fluency": "Native speaker",
      "icon": ""
    },
    {
      "language": "English",
      "fluency": "Fluent",
      "icon": ""
    }
  ],
  "interests": [
    {
      "name": "Machine Learning",
      "icon": "fa-solid fa-tag",
      "keywords": [
        "Image coding for machine",
        "Large language models"
      ]
    }
  ],
  "references": [
    {
      "name": "Professor John Doe",
      "icon": "fa-solid fa-laptop",
      "reference": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam condimentum, diam quis convallis euismod, arcu mi ullamcorper lorem, a vestibulum nunc magna at sem. Sed in risus ac felis varius blandit. D"
    },
    {
      "name": "Professor John Doe",
      "icon": "fa-solid fa-thumbtack",
      "reference": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam condimentum, diam quis convallis euismod, arcu mi ullamcorper lorem, a vestibulum nunc magna at sem. Sed in risus ac felis varius blandit. D"
    }
  ],
  "publications": [
    {
      "name": "TransTIC: Transferring Transformer-based Image Compression from Human Visualization to Machine Perception",
      "publisher": "Yi-Hsin Chen, Ying-Chieh Weng, Chia-Hao  Kao, Cheng Chien, Wei-Chen Chiu, and Wen-Hsiao Peng",
      "releaseDate": "2023",
      "url": "https://arxiv.org/abs/2306.05085",
      "summary": "This work aims for transferring a Transformer-based image compression codec from human perception to machine perception without fine-tuning the codec. We propose a transferable Transformer-based image compression framework, termed TransTIC. Inspired by visual prompt tuning, TransTIC adopts an instance-specific prompt generator to inject instance-specific prompts to the encoder and task-specific prompts to the decoder. Extensive experiments show that our proposed method is capable of transferring the base codec to various machine tasks and outperforms the competing methods significantly. To our best knowledge, this work is the first attempt to utilize prompting on the low-level image compression task."
    },
    {
      "name": "Transformer-based Image Compression with Variable Image Quality Objectives",
      "publisher": "Chia-Hao Kao* , Yi-Hsin Chen* , Cheng Chien, Wei-Chen Chiu, and Wen-Hsiao Peng",
      "releaseDate": "2023",
      "url": "https://arxiv.org/abs/2309.12717",
      "summary": "This paper presents a Transformer-based image compression system that allows for a variable image quality objective according to the user's preference. Optimizing a learned codec for different quality objectives leads to reconstructed images with varying visual characteristics. Our method provides the user with the flexibility to choose a trade-off between two image quality objectives using a single, shared model. Motivated by the success of prompt-tuning techniques, we introduce prompt tokens to condition our Transformer-based autoencoder. These prompt tokens are generated adaptively based on the user's preference and input image through learning a prompt generation network. Extensive experiments on commonly used quality metrics demonstrate the effectiveness of our method in adapting the encoding and/or decoding processes to a variable quality objective. While offering the additional flexibility, our proposed method performs comparably to the single-objective methods in terms of rate-distortion performance."
    },
    {
      "name": "Learned hierarchical b-frame coding with adaptive feature modulation for yuv 4: 2: 0 contente",
      "publisher": "Mu-Jung Chen , Hong-Sheng Xie , Cheng Chien, Wen-Hsiao Peng, and Hsueh-Ming Hang",
      "releaseDate": "1916-03-20",
      "url": "https://arxiv.org/abs/2212.14187",
      "summary": "This paper introduces a learned hierarchical B-frame coding scheme in response to the Grand Challenge on Neural Network-based Video Coding at ISCAS 2023. We address specifically three issues, including (1) B-frame coding, (2) YUV 4:2:0 coding, and (3) content-adaptive variable-rate coding with only one single model. Most learned video codecs operate internally in the RGB domain for P-frame coding. B-frame coding for YUV 4:2:0 content is largely under-explored. In addition, while there have been prior works on variable-rate coding with conditional convolution, most of them fail to consider the content information. We build our scheme on conditional augmented normalized flows (CANF). It features conditional motion and inter-frame codecs for efficient B-frame coding. To cope with YUV 4:2:0 content, two conditional inter-frame codecs are used to process the Y and UV components separately, with the coding of the UV components conditioned additionally on the Y component. Moreover, we introduce adaptive feature modulation in every convolutional layer, taking into account both the content information and the coding levels of B-frames to achieve content-adaptive variable-rate coding. Experimental results show that our model outperforms x265 and the winner of last year's challenge on commonly used datasets in terms of PSNR-YUV."
    }
  ],
  "projects": [
    {
      "name": "Quantum Computing",
      "summary": "Quantum computing is the use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. Computers that perform quantum computations are known as quantum computers.",
      "highlights": ["Quantum Teleportation", "Quantum Cryptography"],
      "startDate": "2018-01-01",
      "endDate": "2018-01-01",
      "url": "https://example.com"
    }
  ]
}
